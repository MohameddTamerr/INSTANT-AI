# DAY13
## Types of Unstractured Database:
 include books, journals, documents, metadata, health records, audio, video, analog data, images, files, and unstructured text such as the body of an e-mail message, Web page, or word-processor document.
## Most Kinds Of The AI Models In All Fields:
### In Medical Field:

<ins> Image analysis models: </ins> These models can process medical images such as X-rays, CT scans, MRI scans, ultrasound images 
and more to detect diseases, measure anatomical structures, segment regions of interest and generate synthetic images

<ins> Natural language processing models:</ins> These models can process medical texts such as clinical notes, reports, literature, transcripts and more 
to extract information, summarize data, generate texts, answer questions and classify documents
<ins> Graph neural network models:</ins> These models can process medical graphs such as electronic health records, molecular structures, 
protein interactions and more to predict outcomes, discover patterns, recommend drugs and infer causal relationships

<ins>Reinforcement learning models:</ins> These models can learn from trial-and-error interactions with medical environments such as surgical procedures, 
intensive care units,robotic arms and more to optimize policies, control actions, simulate scenarios and personalize treatments
###In Business:
<ins>Forecasting models:</ins> These models can predict future trends, demands, sales, revenues, costs and more based on historical and current data

<ins>Optimization models:</ins> These models can find the best solutions for complex problems such as resource allocation, scheduling, pricing, routing and more by using mathematical techniques and algorithms

<ins>Recommendation models:</ins> These models can suggest relevant products, services, content, ads and more to customers or users based on their preferences, behavior, context and feedback

<ins>Anomaly detection models:</ins> These models can identify unusual or suspicious patterns, events, transactions and more that deviate from normal 
expectations or rules by using statistical methods and machine learning techniques

<ins>Sentiment analysis models:</ins> These models can extract and classify the emotions, opinions, attitudes and feelings of customers or users from text,
speech, images and more by using natural language processing and computer vision techniques
### In Engineer
Design models: These models can generate, evaluate and optimize engineering designs based on functional requirements,
constraints and objectives by using generative methods, evolutionary algorithms and multi-objective optimization techniques

Simulation models: These models can simulate the behavior and performance of engineering systems and phenomena under different 
conditions and scenarios by using physics-based models, data-driven models or hybrid models

Testing models: These models can verify and validate the functionality, reliability and safety of engineering systems and components
by using statistical methods, fault detection methods and anomaly detection methods

Diagnosis models: These models can identify and localize the causes and effects of failures, malfunctions and defects in engineering
systems and components by using classification methods, clustering methods and causal inference methods

Control models: These models can regulate and coordinate the actions and interactions of engineering systems and components by using feedback mechanisms,
adaptive methods and reinforcement learning methods
##
### What's Docker:
Docker is a set of platform as a service products that use OS-level virtualization to deliver software in packages called containers. 
The service has both free and premium tiers.
##
### Diffrence Between HTML And XHTML:
HTML and XHTML are both markup languages used to create web pages. XHTML is a stricter and more standardized version of HTML.
XHTML is HTML defined as an XML application. XHTML is supported by all major browsers

##
### Languages secure from data scrape:
Using cookies or Javascript to verify that the visitor is a web browser. This can prevent some bots from accessing the website content.

Introducing Captchas to make sure that the user is a human. This can deter automated scraping tools that cannot solve Captchas.

Setting limits on requests and connections. This can prevent excessive scraping that can overload the server or affect the website performance.

Obfuscating or hiding data. This can make it harder for scrapers to find and extract the relevant data from the website.

Detecting and blocking known malicious sources. This can prevent scrapers from specific IP addresses or domains from accessing the website.

Detecting and blocking site scraping tools. This can prevent scrapers that use identifiable signatures or headers from accessing the website.

Constantly updating the HTML tags of the page. This can make it harder for scrapers to parse the website content and follow a consistent pattern

Encrypting or hashing sensitive data. This can prevent scrapers from reading or reusing the data without authorization.

Implementing data protection policies and regulations. This can ensure that the website complies with the legal and ethical standards of data collection and processing, such as GDPR.
